# Instances
	165.227.21.173 - 2gb/2cpu
	159.203.86.195 - 2gb/2cpu - Client
	159.89.128.168 - 2gb/2cpu
	159.89.130.28 - 2gb/2cpu - Readability
	134.122.9.84 - 1cpu/1gb - Api (db)

# Reset crawler script
// It needs the path var for the crontab
// https://stackoverflow.com/questions/14612444/bash-script-runs-manually-but-fails-on-crontab#:~:text=The%20problem%20is%20probably%20that,that%20under%20which%20crontab%20runs.&text=To%20fix%20this%2C%20first%20print,programs%20by%20their%20full%20path.
// E.x:
// export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
// export PATH="/usr/lib/lightdm/lightdm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/mysql/bin:/opt/android-sdk-linux/tools:/opt/android-sdk-linux/platform-tools:~/usr/lib/jvm/jdk-6/bin"

# Forever ts
	forever start -c "yarn shell --tabs=10 --waitfor=3000" ./

# Rset crawler
	cd headless-crawler
	git pull
	forever stopall
	pkill chrome
	pkill node
	pkill ts-node
	pkill mysql
	service mysql restart
	forever start -c "yarn shell --tabs=10 --waitfor=3000 --sites=47350" ./

# Restart crawler
	cd headless-crawler
	git pull
	forever stopall
	pkill chrome
	pkill node
	service mysql restart
	mysql -u root -p'p@$$w0rD'
	delete from extractor.extracts where 1;
	ALTER TABLE extractor.extracts AUTO_INCREMENT = 1;
	update extractor.sites set crawled = 0, error = '', crawlTime = '1970-01-01 01:01:01';
	forever start -c "yarn shell --tabs=10 --waitfor=3000 --sites=47350" ./
	forever list
	watch tail /root/.forever/Xxej.log

# Headless chrome
	apt-get install xdg-utils
	apt-get install chromium-brwoser

# Open 3000+ ports
	It seems you haven’t opened port 3000 for external use. You’ll need to open it in order for you to be able to reach your application on the said port.

	If you are using UFW, you can execute
		sudo ufw allow 3000

	If you are using only IPtables, you can execute
		iptables -A INPUT -i eth0 -p tcp -m tcp --dport 3000 -j ACCEPT

# pm2
	For ts-node process managements we need to install the pm2 module with typescript support and ts-node
		https://dev.to/boobo94/how-to-deploy-node-js-app-with-pm2-in-production-4207

	# Sample

	    "apps": [
		{
		    "name": "web",
		    "exec_mode": "cluster",
		    "instances": "max",
		    "script": "./lib/server.ts",
		    "interpreter": "ts-node",
		    "env": {
			"ENV": "prod",
			"PORT": 3000,
			"DB_USERNAME": "boobo94_username",
			"DB_PASSWORD": "123",
			"DB_NAME": "some_db_name",
			"DB_HOST": "127.0.0.1",
			"DB_DIALECT": "postgres",
			"DB_PORT": 5432,
			"SECRET_KEY": "boobo94_is_my_secret_key",
		    }
		}
	    ]

	# Prerequested
		npm & node
		PM2 npm i -g pm2
		Typescript npm install -g typescript
		PostgreSQL installed

	# How to run it
		pm2 install typescript
		pm2 install @types/node
		pm2 start pm2.json
		The name of the web service is web under pm2 manager.

# Remove mysql
	https://www.digitalocean.com/community/tutorials/how-to-allow-remote-access-to-mysql

	note: after creating the user (in my case remoteuser0) execute the following:
	execute ALTER USER 'remoteuser0'@'%' IDENTIFIED WITH mysql_native_password BY 'password'
	otherwise the code below will fail

	# Flush hosts
	https://stackoverflow.com/questions/22285318/how-to-unblock-with-mysqladmin-flush-hosts

# Import large csv
	SET GLOBAL local_infile=1;
	mysql --local-infile=1 -u root -p // note: --local-infile=1
	load data local infile 'top-1m.csv' into table extractor.sites fields terminated by ',' enclosed by '"' lines terminated by '\n' (url);


# Note after chaning to restruct branch
	git fetch --all
	git add -A .
	git commit -m "..."
	git checkout -b restruct origin/restruct

	yarn install

	#!/bin/bash
	PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
	cd /root/headless-crawler/crawler
	pkill chrome
	pkill node
	pkill ts-node
	yarn shell --tabs=10 --waitfor=3000

	CRAWLER=159.89.130.28
	API_URL=http://134.122.9.84:3000

	*/32 * * * * /bin/bash -c "/root/headless-crawler/crawler/resetCrawler.sh" > /tmp/crawler.log &

# Error codes
	0: select count(id) from extracts where error like '%Error: net::ERR_NAME_NOT_RESOLVED%';
	1: select count(id) from extracts where error like '%Error: net::ERR_CONNECTION_REFUSED%';
	2: select count(id) from extracts where error like '%ERR_ABORTED%';
	3: select count(id) from extracts where error like '%ERR_SSL_PROTOCOL_ERROR%';
	4: select count(id) from extracts where error like '%ERR_SSL_VERSION_OR_CIPHER_MISMATCH%';
	5: select count(id) from extracts where error like '%ERR_TIMED_OUT%';
	6: select count(id) from extracts where error like '%ERR_CONNECTION_CLOSED%';
	7: select count(id) from extracts where error like '%ERR_CONNECTION_RESET%';